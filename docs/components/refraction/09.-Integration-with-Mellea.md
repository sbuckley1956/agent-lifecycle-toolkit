# Mellea ft. Refraction

[Mellea](https://mellea.ai) is an open-source library from IBM for writing generative programs.
Mellea allows you to write structured instructions for your agents with off-the-shelf validators
and prompting and sampling patterns.

Refraction is a low-cost (no LLMs!), low-latency, domain-agnostic, data-agnostic, model-agnostic
approach towards validation and repair for a sequence of tool calls.

Naturally, a perfect fit. ðŸ¤—

The following is an example of an external integration.
Since tool calling is one of the most dominant usage patterns of agentic systems,
we would ideally like to make this integration available as a built-in requirement
specialized for validating tool calling sequences.

# 9.1 Mellea Requirements

The first point of integration is with [Mellea requirements](https://docs.mellea.ai/overview/requirements#validating-requirements).
These are in-built validators that operate on the output of a model
to make sure things we care about are maintained in the output.

For refraction, we care about the tool-calling part of the output -- this means, we
want to make sure that the tool calls adhere to the tools specs, they flow of data
between subsequent tool calls are following the specs, there is no redundant steps,
there is no missing step, and so on. All the usual cool refraction stuff!

For a simple example of passing the refraction requirement, try [this test](https://github.com/AgentToolkit/agent-lifecycle-toolkit/blob/main/tests/pre-tool-reflection/refraction/mellea/test_mellea.py#L26).

```python
from refraction.integration.mellea_requirement import RefractionRequirement

mellea_session = start_session()
refractor_req = RefractionRequirement(tools=tools)

inference_result = mellea_session.instruct(
    description=...,
    requirements=[
        refractor_req,
    ],
    user_variables={
        "query": (
            "I need a travel approval to present my conference papers."
            " My email is tchakra2@ibm.com"
        ),
        "tools": tools,
        "memory": {},
    },
)

assert inference_result.success is True
```

You can find the tools used for this example [here](https://github.com/AgentToolkit/agent-lifecycle-toolkit/blob/main/tests/utils/refraction/tools/sample_tool_specs.py),
and the prompt [here](https://github.com/AgentToolkit/agent-lifecycle-toolkit/blob/main/tests/utils/refraction/mellea/prompt.py).
The sequence of calls produced by the LLM, as shown below, passes the refraction test.

```
<tool_calls>[
{"name": "w3", "args": {"email": "tchakra2@ibm.com"}, "label": "var1"},
{"name": "author_workbench", "args": {"id": "$var1.id"}, "label": "var2"},
{"name": "concur", "args": {"employee_info": "$var1", "travel_justification": [{"paper": "$var2.papers"}]}, "label": "var3"}
]</tool_calls>
```

# 9.2 Mellea Sampling

When the requirement is not met, refraction can do two things: 1) recommend a fixed sequence if possible; and 2) provide a
new prompt as feedback to a new call to an LLM. For Mellea, this becomes a sampling step.

> ðŸ’¡ This is the same two stage usage of refraction as described [here](02.-The-Refraction-API-%7C-Inputs-and-Outputs.md#224-prompt-generation), but now built into the Mellea instruct-validate-repair paradigm.

In [this test](https://github.com/AgentToolkit/agent-lifecycle-toolkit/blob/main/tests/pre-tool-reflection/refraction/mellea/test_mellea.py#L77),
we have intentionally messed up the LLM response to demonstrate this.
We have removed a parameter in the call to the `concur` tool. The requirement responds
by 1) flagging a failure; 2) computing a fixed call;
and 3) a new prompt for the next sampling step (instead of retrying with the same prompt).


```python
from refraction.integration.mellea_requirement import (
    RefractionRequirement,
    refract_repair,
)

mellea_session = start_session()
refractor_req = RefractionRequirement(tools=tools)

inference_result = self.mellea_session.instruct(
    description=...,
    requirements=[
        refractor_req,
    ],
    user_variables={
        "query": ...,
        "tools": tools,
        "memory": {},
    },
    strategy=RejectionSamplingStrategy(
        loop_budget=2, repair=refract_repair
    ),
    return_sampling_results=True,
)

assert inference_result.success is False
```

```
  var1 = w3(email="tchakra2@ibm.com")
  var2 = author_workbench(id="$var1.id$")
  var3 = hr_bot(id="$var1.id$", email="tchakra2@ibm.com")
- var4 = concur(travel_justification="$var2.papers$")
+ var4 = concur(employee_info="$var3.info$", travel_justification="$var2.papers$")
?               +++++++++++++++++++++++++++++
```

```
print(inference_result.sample_validations[0][0][1].reason)
```

```
Please fix the provided tool call based on the issues outlined.

<tool_call>[
{'name': 'w3', 'arguments': {'email': 'tchakra2@ibm.com'}, 'label': 'var1'},
{'name': 'author_workbench', 'arguments': {'id': '$var1.id$'}, 'label': 'var2'},
{'name': 'hr_bot', 'arguments': {'id': '$var1.id$', 'email': 'tchakra2@ibm.com'}, 'label': 'var3'},
{'name': 'concur', 'arguments': {'travel_justification': '$var2.papers$'}, 'label': 'var4'}
]</tool_call>

The following are the identified issues:
Each issue is accompanied by guidance on how to fix it.
Consider the guidance, along with the provided tool specs, and memory, to come up with the final fixed tool call.

- Parameter employee_info is a required parameter for concur, but it is missing.
- Possible fix: Get value of parameter employee_info by calling hr_bot.
```

For a range of feedback provided by the refractor, take a look at some
cached prompts [here](https://github.com/AgentToolkit/agent-lifecycle-toolkit/blob/main/tests/pre-tool-reflection/refraction/prompt_generation/cached_prompts).

# 9.3 Gaps for a more perfect union

While the above examples are enough to get us started, we could do
much more (and have a much slicker dev interface to the refraction requirement)
if the following were possible:

- I could not see any immediate method to access the prompt / instruction
(and not just the response) inside the requirement.
This should be possible, and then we would not require any extra inputs (i.e. tools, memory, etc.) at all
to instantiate the requirement -- we can read off everything from the instruction. [[link](https://github.com/AgentToolkit/agent-lifecycle-toolkit/blob/main/altk/pre_tool/refraction/src/integration/mellea_requirement.py#L12)]

- Currently, the validation result only allows for a `str` reason. This means that the refractor, in the
event it could fix a call in situ, as in the example above, it must use the prompting mechanism for resampling.
An alternative pathway could be to allow for return the fix in the validator, if it is able to fix in place, and this
saves us an extra sampling cost + avoid the possibility of ending up with a new error in the new sample. [[link](https://github.com/AgentToolkit/agent-lifecycle-toolkit/blob/main/altk/pre_tool/refraction/src/integration/mellea_requirement.py#L19)]
