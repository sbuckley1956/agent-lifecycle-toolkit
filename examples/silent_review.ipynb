{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21531c26",
   "metadata": {},
   "source": [
    "# Demo of Silent Review\n",
    "This Jupyter notebook is a demo of a post tool reflection component.\n",
    "\n",
    "This component is a prompt-based approach to identify silent errors in tool calls (errors that do not produce any visible or explicit error message) by determining whether the tool response is relevant, accurate and complete based on the user's query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57876e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.prebuilt import InjectedState\n",
    "\n",
    "from altk.post_tool.silent_review.silent_review import (\n",
    "    SilentReviewForJSONDataComponent,\n",
    ")\n",
    "from altk.post_tool.core.toolkit import SilentReviewRunInput, Outcome\n",
    "from altk.core.toolkit import AgentPhase, ComponentConfig\n",
    "from altk.core.llm import get_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a752c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the following environment variables are set:\n",
    "# OPENAI_API_KEY = *** openai api key ***\n",
    "# LLM_PROVIDER = openai.sync\n",
    "# MODEL_NAME = o4-mini\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"\n",
    "\n",
    "OPENAI_CLIENT = get_llm(\"openai.sync\")\n",
    "config = ComponentConfig(\n",
    "    llm_client=OPENAI_CLIENT(\n",
    "        model_name=\"o4-mini\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd9c23",
   "metadata": {},
   "source": [
    "Create a get_weather mock tool that returns a temperature given a city. For simplicity, we include the silent review call in the tool function. However, you can integrate the silent review component differently, based on the architecture of your agents and tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str, state: Annotated[dict, InjectedState]) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    if random.random() >= 0.500:\n",
    "        # Simulates a silent error from an external service\n",
    "        result = {\"weather\": \"Weather service is under maintenance.\"}\n",
    "    else:\n",
    "        result = {\"weather\": f\"It's sunny and 70F in {city}!\"}\n",
    "\n",
    "    # Use SilentReview component to check if it's a silent error\n",
    "    review_input = SilentReviewRunInput(\n",
    "        messages=state[\"messages\"], tool_response=result\n",
    "    )\n",
    "    reviewer = SilentReviewForJSONDataComponent()\n",
    "    review_result = reviewer.process(data=review_input, phase=AgentPhase.RUNTIME)\n",
    "\n",
    "    if review_result.outcome != Outcome.ACCOMPLISHED:\n",
    "        # Agent should retry tool call if silent error was detected\n",
    "        return \"Silent error detected, retry the get_weather tool!\"\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf077f",
   "metadata": {},
   "source": [
    "Create a simple ReAct agent to demonstrate the silent review component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0616368",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=\"openai:o4-mini\", tools=[get_weather], prompt=\"You are a helpful assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692368a1",
   "metadata": {},
   "source": [
    "Run the agent and print the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
